{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation Example\n",
    "This notebook gives an example of how to use [pyshepseg](https://www.pyshepseg.org) to segment an image of any size, extract statistics associated with the segments and create a vector version of the output.\n",
    "\n",
    "You'll need to install both [RIOS](https://www.rioshome.org/en/latest/#downloads) and [pyshepseg](https://www.pyshepseg.org/en/latest/#installation) to make this work, ideally in a new environment.\n",
    "\n",
    "Note that there seems to be a bug in the statistics generation that I think is related to the use of JPEG compression in tiff files. If statistics are not generated, try first translating the image using something like:\n",
    "```\n",
    "gdal_translate -of GTiff -co COMPRESS=DEFLATE -co TILED=YES -co BIGTIFF=YES INFILE_COMPRESSTED_WITH_JPEG.tif OUTFILE_COMPRESSED_WITH_DEFLATE.tif\n",
    "```\n",
    "\n",
    "To run this it might be useful to set up a new environment\n",
    "f you're new to this, I'd recommend starting with [Miniconda](https://docs.conda.io/en/latest/miniconda.html) then installing the required packages in a new environment. I'd also recommend replacing conda with mamba to speed up the solving of python dependencies. Something like this should work:\n",
    "```\n",
    "conda create --name seg python=3.9\n",
    "conda activate seg \n",
    "conda install -c conda-forge mamba\n",
    "mamba install -c conda-forge jupyterlab rios gdal numpy numba pip scikit-learn\n",
    "```\n",
    "\n",
    "Then either use the copy of pyshepseg in this repo, or (much) better install it using the [install directions](https://www.pyshepseg.org/en/latest/#installation) on the pyshepseg website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First we import the required packages\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyshepseg import shepseg\n",
    "from pyshepseg import tiling\n",
    "from pyshepseg import utils\n",
    "from rios import applier\n",
    "from rios import rat\n",
    "from rios import ratapplier\n",
    "from osgeo import gdal\n",
    "from osgeo import ogr\n",
    "from osgeo import osr\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Utility function to get the nodata vaues of a raster\n",
    "def getNodata(raster):\n",
    "    raster = gdal.Open(raster)\n",
    "    band = raster.GetRasterBand(1)\n",
    "    nodata = band.GetNoDataValue()\n",
    "    return nodata\n",
    "\n",
    "\n",
    "# Filenames used in this notebook\n",
    "RASTER = '14MAY28105005-S3DS-subset.tif'\n",
    "LAYERNAME=os.path.splitext(os.path.basename(RASTER))[0]\n",
    "OUTFILE = LAYERNAME + '.kea'\n",
    "RGBFILE = LAYERNAME + '_rgb.tif'\n",
    "IDFILE = LAYERNAME + '_id.tif'\n",
    "SEGFILE = LAYERNAME + '_seg.gpkg'\n",
    "CSVFILE = LAYERNAME + '_rat.csv'\n",
    "\n",
    "# Get the NoData value of the input file\n",
    "noData = getNodata(RASTER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the tiled segmenter\n",
    "This takes a while to run, and the initiAL KMEANs clustering can take hours for large images.\n",
    "\n",
    "The process works by segmenting tiles. These need to be small enough to fit in memory, with enough overlap so they stitch together neatly at the end.\n",
    "\n",
    "There are quite a few options that control the segmentation, in particular minSegmentSize is the minimum segment size (in pixels) which will be left after eliminating small segments (except for segments which cannot be eliminated) and maxSpectralDiff sets a limit on how different segments can be and still be merged. It is given in the units of the spectral space of img. If maxSpectralDiff is ‘auto’, a default value will be calculated from the spectral distances between cluster centres, as a percentile of the distribution of these (spectDistPcntile). The value of spectDistPcntile should be lowered when segementing an image with a larger range of spectral distances. If fourConnected is True, then use 4-way connectedness when clumping, otherwise use 8-way connectedness. Default values are mostly as suggested by Shepherd et al.\n",
    "\n",
    "By default this writes a [KEA](http://www.kealib.org/) format image, as we make extensive use of the raster attribute table to store data.\n",
    "\n",
    "After the segmentation, we also calculate histograms and some statistics on the segment IDs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting tiled segmentation\n",
      "KMeans of whole raster 6.01 seconds\n",
      "Subsample Percentage=1.00\n",
      "Found 2 tiles, with 1 rows and 2 cols\n",
      "\n",
      "Doing tile 1 of 2: row=0, col=0\n",
      "Kmeans, in 0.7 seconds\n",
      "Found 11364647 clumps, in 1.2 seconds\n",
      "Eliminated 8157153 single pixels, in 2.3 seconds\n",
      "Eliminated 3205868 segments, in 268.0 seconds\n",
      "Final result has 1626 segments\n",
      "\n",
      "Doing tile 2 of 2: row=0, col=1\n",
      "Kmeans, in 0.9 seconds\n",
      "Found 14718709 clumps, in 0.7 seconds\n",
      "Eliminated 10485658 single pixels, in 2.0 seconds\n",
      "Eliminated 4229150 segments, in 337.1 seconds\n",
      "Final result has 3901 segments\n",
      "Stitching tiles together\n",
      "Stitching tile row 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TILE_SIZE = 4096 # Set this so the tiles fit in memory\n",
    "OVERLAP_SIZE = TILE_SIZE // 16\n",
    "MIN_PIXELS = 10000 # Minimum number of pixels in a segment to be considered a valid segment = 2500 m2\n",
    "\n",
    "# Run the tiles segmentation\n",
    "tiledSegResult = tiling.doTiledShepherdSegmentation(RASTER, OUTFILE, \n",
    "        tileSize=TILE_SIZE, overlapSize=OVERLAP_SIZE, \n",
    "        minSegmentSize=MIN_PIXELS, numClusters=60,\n",
    "        bandNumbers=None, subsamplePcnt=1,\n",
    "        maxSpectralDiff='auto', imgNullVal=noData,\n",
    "        fixedKMeansInit=False, spectDistPcntile=50,\n",
    "        fourConnected=True, verbose=True,\n",
    "        simpleTileRecode=False, outputDriver='KEA')\n",
    "\n",
    "\n",
    "# Build the histogram, segment stats and colour table on the KEA file. \n",
    "outDs = gdal.Open(OUTFILE, gdal.GA_Update)\n",
    "# This builds the histogram of segmentIDs\n",
    "hist = tiling.calcHistogramTiled(outDs, tiledSegResult.maxSegId, writeToRat=True)\n",
    "# This gets the band object representing the segmentIDs\n",
    "band = outDs.GetRasterBand(1)\n",
    "# This adds metadata back into the KEA file making it easier to open and view\n",
    "utils.estimateStatsFromHisto(band, hist)\n",
    "# Uncomment this to write a random color table to the KEA file\n",
    "#utils.writeRandomColourTable(band, tiledSegResult.maxSegId+1)\n",
    "\n",
    "# Close the KEA file\n",
    "del outDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Zonal Statistics \n",
    "The calcPerSegmentStatsTiled is a very efficient way to calculate various statistics for each segment.\n",
    "\n",
    "A routine is provided to do this in a memory-efficient way, given the original image and the completed segmentation image. \n",
    "\n",
    "A standard set of statistics are available, including mean, standard deviation, and arbitrary percentile values, amongst others. \n",
    "\n",
    "The selected per-segment statistics are written to the segment image file as columns of a raster attribute table (RAT).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the RGB Stats from the input image\n",
    "for imgbandnum in [1,2,3]:\n",
    "    statsSelection = [\n",
    "        ('band_{}_mean'.format(imgbandnum), 'mean'),  # Calculate the mean per segment\n",
    "        ('band_{}_std'.format(imgbandnum), 'stddev')] # Calculate the standard deviation per segment\n",
    "    tiling.calcPerSegmentStatsTiled(RASTER, imgbandnum, OUTFILE,statsSelection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the segment ID and the segment means to GeoTiff images \n",
    "This uses the RIOS library to link the segment ID to the corresponding KEA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the RIOS inputs and Outputs\n",
    "infiles = applier.FilenameAssociations()\n",
    "outfiles = applier.FilenameAssociations()   \n",
    "infiles.image = OUTFILE\n",
    "outfiles.id = IDFILE\n",
    "outfiles.rgb = RGBFILE\n",
    "\n",
    "# Other inputs include the columns representing the mean values \n",
    "otherargs = applier.OtherInputs()\n",
    "otherargs.b1 = np.round(rat.readColumn(OUTFILE,'band_1_mean')).astype(np.uint16)\n",
    "otherargs.b2 = np.round(rat.readColumn(OUTFILE,'band_2_mean')).astype(np.uint16)\n",
    "otherargs.b3 = np.round(rat.readColumn(OUTFILE,'band_3_mean')).astype(np.uint16)\n",
    "otherargs.noData = noData\n",
    "\n",
    "# Set up RIOS controls\n",
    "controls = applier.ApplierControls()\n",
    "controls.windowxsize = 512\n",
    "controls.windowysize = 512\n",
    "controls.setStatsIgnore(noData)\n",
    "controls.setOutputDriverName(\"GTIFF\")\n",
    "controls.setCreationOptions([\"COMPRESS=DEFLATE\",\n",
    "                             \"ZLEVEL=9\",\n",
    "                             \"BIGTIFF=YES\",\n",
    "                             \"TILED=YES\",\n",
    "                             \"INTERLEAVE=BAND\",\n",
    "                             \"NUM_THREADS=ALL_CPUS\",\n",
    "                             \"BLOCKXSIZE=512\",\n",
    "                             \"BLOCKYSIZE=512\"])\n",
    "\n",
    "# Function applied on image tiles using RIOS applier to extract the segment means\n",
    "def _exportColor(info,inputs,outputs,otherargs):   \n",
    "    # Get the input segment IDs\n",
    "    data = inputs.image\n",
    "    # Get the input array shape\n",
    "    inshape = data.shape\n",
    "    # Flatten the segment id array\n",
    "    data = np.reshape(data,-1)\n",
    "    # Use the segment ids as keys into the band mean attributes\n",
    "    b1 = (otherargs.b1)[data]\n",
    "    b2 = (otherargs.b2)[data]\n",
    "    b3 = (otherargs.b3)[data]\n",
    "    # Stack the segmtn means into a three band image\n",
    "    rgb = np.vstack((b1,b2,b3))\n",
    "    # Reshape the outputs to match the input shape\n",
    "    outputs.id =  np.reshape(data,(1,inshape[1],inshape[2])).astype(np.uint32)\n",
    "    outputs.rgb =  np.reshape(rgb,(3,inshape[1],inshape[2])).astype(np.uint16)\n",
    "\n",
    "# Apply the function\n",
    "applier.apply(_exportColor, infiles, outfiles, otherargs, controls=controls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a vector file\n",
    "Sometimes you might want to vectorize the output.\n",
    "\n",
    "This is a much faster version of [gdal_polygonize.py](https://gdal.org/programs/gdal_polygonize.html) as it writes the entire file in one transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Raster\n",
    "outDs = gdal.Open(IDFILE)\n",
    "band = outDs.GetRasterBand(1)\n",
    "# Create the vector\n",
    "vecDs = ogr.GetDriverByName(\"GPKG\").CreateDataSource(SEGFILE)\n",
    "vecLayer = vecDs.CreateLayer('segid', srs=osr.SpatialReference(wkt=outDs.GetProjection()))\n",
    "vecLayer.CreateField(ogr.FieldDefn('segid', ogr.OFTInteger))\n",
    "# Polygonize\n",
    "vecDs.StartTransaction()\n",
    "gdal.Polygonize( band, None, vecLayer, 0, [], callback=None)\n",
    "vecDs.CommitTransaction()\n",
    "# Close the raster and vector\n",
    "del outDs\n",
    "del vecDs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the raster attribues into a CSV file\n",
    "This is a utility function that just pulls the raster attributes into a simple CSV file that you can join to the vector file or perform additional analysis on (such as classification or clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column names\n",
    "colNames = rat.getColumnNames(OUTFILE)\n",
    "# Read the data into an array\n",
    "allData = np.transpose([rat.readColumn(OUTFILE,name) for name in colNames])\n",
    "# Add an index column\n",
    "allData = np.vstack((np.arange(len(allData)),allData.T)).T\n",
    "# Make a header\n",
    "colNames.insert(0,'Index')\n",
    "header = ','.join(colNames)\n",
    "# Write the file\n",
    "np.savetxt(CSVFILE,allData,fmt='%8.3f',delimiter=',',header=header,comments='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8478c2d4f27a82cd614f45fc3a5825e5be922b827d02cab10c48ce312e9ff789"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
